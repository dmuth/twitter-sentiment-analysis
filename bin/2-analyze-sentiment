#!/usr/bin/env python3
# Vim: :set softtabstop=0 noexpandtab tabstop=4

import argparse
import boto3
import json
import logging as logger
import logging.config
import sqlite3
import sys
import time

sys.path.append("lib")
import db


#
# Set up the logger
#
logging.config.fileConfig("logging_config.ini", disable_existing_loggers = True)

#
# Parse our arguments
#
parser = argparse.ArgumentParser(description = "Analyze crawled text")
parser.add_argument("-n", "--num", type = int, help = "How many tweets to analyze? (Default: 5)", default = 5)
parser.add_argument("--fake", action = "store_true", help = "Fake AWS calls")
parser.add_argument("--loop", type = int, help = "Loop after sleeping for N seconds")
args = parser.parse_args()


#
# Analyize a batch of tweets
#
# @param object comprehend - Object that lets us connect to AWS
# @param list batch - Array of tweets
# @param boolean fake - Are we faking calling Amazon?
#
# @return array An array of dictionaries where each element is the tweet_id, tweet, and sentiment.
#
def analyze(comprehend, batch, fake):

	logger.info("Analyzing batch of %d tweets..." % len(batch))
	tweets = [row["tweet"] for row in batch]

	if fake:
		#
		# We're faking a call to AWS, which is useful for testing.
		#
		results = []

		#
		# Fake sentiment values
		#
		values = [ 
			{"Sentiment": "POSITIVE", "Score": { "Positive": 0.9, "Negative": 0.5, "Mixed": 0.5, "Neutral": 0.5 } },
			{"Sentiment": "NEGATIVE", "Score": { "Positive": 0.5, "Negative": 0.9, "Mixed": 0.5, "Neutral": 0.5 } },
			{"Sentiment": "MIXED", "Score": { "Positive": 0.5, "Negative": 0.5, "Mixed": 0.9, "Neutral": 0.5 } },
			{"Sentiment": "NEUTRAL", "Score": { "Positive": 0.5, "Negative": 0.5, "Mixed": 0.5, "Neutral": 0.9 } }
			]
                       
		#
		# Now loop through our tweets, grab a different sentiment for each, and store the results.
		#
		index = 0
		for row in tweets:

			fake_sentiment_value = values[index % 4]

			results.append({
				"Index": index, 
				"Sentiment": fake_sentiment_value["Sentiment"],
				"SentimentScore": fake_sentiment_value["Score"]
				})
			index += 1

	else:
		results = comprehend.batch_detect_sentiment(TextList = tweets, LanguageCode='en')
		results = results["ResultList"]


	#
	# Go through our results (real or fake), and put them into a common data structure
	# which is then returned.
	#
	for result in results:

		index = result["Index"]
		sentiment = result["Sentiment"]
		score = result["SentimentScore"]

		batch[index]["sentiment"] = sentiment
		batch[index]["score"] = score

	return(batch)


#
# @param object sql Our SQLite object
# @param list batch - Array of tweets and their sentiments
#
def writeResults(sql, batch):

	query = "UPDATE tweets SET score=?, sentiment=? WHERE rowid=?"
	for row in batch:
		sql.execute(query, [ json.dumps(row["score"]), row["sentiment"], row["rowid"] ])



#
# Our main entry point
#
def main(args):

        #
        # Flush stdout as that doesn't seem to happen regularly in Docker.
        # This is mostly of use when debugging.
        #
	sys.stdout.flush()

	comprehend = boto3.client(service_name='comprehend', region_name='us-east-1')

	#
	# Set the database to return associative arrays
	#
	sql = db.db()
	sql.conn.row_factory = sqlite3.Row

	query = ("SELECT rowid, tweet_id, tweet FROM tweets "
		"WHERE "
		#
		# This allows us to run on tweets that were previously fake-analyzed.
		#
		"(sentiment = '' OR sentiment LIKE 'TEST%%') "
		"LIMIT %d " % (args.num))
	results = sql.execute(query)

	logger.info("Analyzing up to %d tweets." % (args.num))

	batch_size = 25

	batch = []
	num_analyzed = 0

	for row in results:
	
		if len(batch) >= batch_size:
		
			batch = analyze(comprehend, batch, args.fake)
			writeResults(sql, batch)
			num_analyzed += len(batch)
			batch = []

		batch.append({
			"rowid": row["rowid"],
			"tweet": row["tweet"]
			})
	
	if batch:
		batch = analyze(comprehend, batch, args.fake)
		writeResults(sql, batch)
		num_analyzed += len(batch)

	cost = 0.0003 * num_analyzed
	logger.info("total_tweets_analyzed=%d" % num_analyzed)
	logger.info("total_aws_cost=%.4f" % cost)
	if args.fake:
		logger.info("BUT--this was run with --fake, so your total cost is really ZERO! :-)")

	logger.info("ok=1")

        #
        # Flush stdout as that doesn't seem to happen regularly in Docker
        # This is mostly of use when debugging.
        #
	sys.stdout.flush()

if not args.loop:
	main(args)

else:
	while True:
		main(args)
		logger.info("Sleeping for %d seconds..." % args.loop)
		time.sleep(args.loop)
		logger.info("Waking up!")




