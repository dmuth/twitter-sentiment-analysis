#!/usr/bin/env python3
# Vim: :set softtabstop=4 noexpandtab tabstop=4

import argparse
import boto3
import json
import logging as logger
import logging.config
import sqlite3
import sys
import time

sys.path.append("lib")
import db


#
# Set up the logger
#
logging.config.fileConfig("logging_config.ini", disable_existing_loggers = True)

#
# Parse our arguments
#
parser = argparse.ArgumentParser(description = "Analyze crawled text")
parser.add_argument("-n", "--num", type = int, help = "How many tweets to analyze? (Default: 5)", default = 5)
parser.add_argument("--fake", action = "store_true", help = "Fake AWS calls")
parser.add_argument("--skip", type = int, help = "How many tweets to skip after every analyzed/fake tweet? (Default: 0)", default = 0)
parser.add_argument("--loop", type = int, help = "Loop after sleeping for N seconds")
args = parser.parse_args()

#print("Debug Args:", args); sys.exit(1) # Debugging

#
# A global variable that holds how many tweets are left to skip.
# This is a little dumb, but was added late in the game.  If I were
# to start over, I might put all the code into a class instead.
#
skip_left = args.skip



#
# We're skipping an analysis of the tweet, so just have plain values here.
#
def getSkipAnalysis():
	retval = {"Sentiment": "skipped", "Score": { "Positive": 0, "Negative": 0, "Mixed": 0, "Neutral": 0 } }
	return(retval)


#
# Get fake analysis for a series of tweets, with optional skipping!
#
# @param tweets batch - Array of tweets
# @param integer skip - Are we skipping analysis/faking?  If so, this 
#   value is non-zero and is the number of tweets skipped each time.
#
def getFakeAnalysis(tweets, skip):
	
	#
	# Yeah, this is a global variable.  I am *really* not proud of this.
	#
	global skip_left

	#
	# We're faking a call to AWS, which is useful for testing.
	#
	results = []

	#
	# Fake sentiment values, which are rotated through.
	#
	values = [ 
		{"Sentiment": "fake_POSITIVE", "Score": { "Positive": 0.9, "Negative": 0.5, "Mixed": 0.5, "Neutral": 0.5 } },
		{"Sentiment": "fake_NEGATIVE", "Score": { "Positive": 0.5, "Negative": 0.9, "Mixed": 0.5, "Neutral": 0.5 } },
		{"Sentiment": "fake_MIXED", "Score": { "Positive": 0.5, "Negative": 0.5, "Mixed": 0.9, "Neutral": 0.5 } },
		{"Sentiment": "fake_NEUTRAL", "Score": { "Positive": 0.5, "Negative": 0.5, "Mixed": 0.5, "Neutral": 0.9 } }
		]
                       
	#
	# Now loop through our tweets, grab a different sentiment for each, and store the results.
	#
	index = 0
	for row in tweets:

		if (skip):
			
			#
			# If there are tweets left to skip, get the skip data and decrement the counter.
			#
			if (skip_left > 0):
				fake_sentiment_value = getSkipAnalysis()
				skip_left -= 1

			else:
				#
				# If we went through our current amount of tweets to skip,
				# grab a fake sentiment value instead and reset the skip counter.
				#
				fake_sentiment_value = values[index % 4]
				skip_left = skip


		else: 
			#
			# Not skipping?  Oh, okay.  Just grab the fake sentiment value!
			#
			fake_sentiment_value = values[index % 4]

		results.append({
			"Index": index, 
			"Sentiment": fake_sentiment_value["Sentiment"],
			"SentimentScore": fake_sentiment_value["Score"]
			})
		index += 1

	return(results)


#
# Analyize a batch of tweets
#
# @param object comprehend - Object that lets us connect to AWS
# @param list batch - Array of tweets
# @param boolean fake - Are we faking calling Amazon?
# @param integer skip - Are we skipping analysis/faking?  If so, this 
#   value is non-zero and is the number of tweets skipped each time.
#
# @return array An array of dictionaries where each element is the tweet_id, tweet, and sentiment.
#
def analyze(comprehend, batch, fake, skip):

	logger.info("Analyzing batch of %d tweets..." % len(batch))
	tweets = [row["tweet"] for row in batch]

	if fake:
		results = getFakeAnalysis(tweets, skip)

	else:
		results = comprehend.batch_detect_sentiment(TextList = tweets, LanguageCode='en')
		results = results["ResultList"]


	#
	# Go through our results (real or fake), insert them back into the batch 
	# (which contains the rest of the data on that tweet, such as username), 
	# and return the modified batch.
	#
	for result in results:

		index = result["Index"]
		sentiment = result["Sentiment"]
		score = result["SentimentScore"]

		batch[index]["sentiment"] = sentiment
		batch[index]["score"] = score

	return(batch)


#
# @param object sql Our SQLite object
# @param list batch - Array of tweets and their sentiments
#
def writeResults(sql, batch):

	query = "UPDATE tweets SET score=?, sentiment=? WHERE rowid=?"
	for row in batch:
		sql.execute(query, [ json.dumps(row["score"]), row["sentiment"], row["rowid"] ])



#
# Our main entry point
#
def main(args):

	#
	# Flush stdout as that doesn't seem to happen regularly in Docker.
	# This is mostly of use when debugging.
	#
	sys.stdout.flush()

	comprehend = boto3.client(service_name='comprehend', region_name='us-east-1')

	#
	# Set the database to return associative arrays
	#
	sql = db.db()
	sql.conn.row_factory = sqlite3.Row

	#
	# While it shouldn't matter, we're grabbing these tweets in order, because it
	# makes it much easier to audit the logic for skipping.
	#
	query = ("SELECT rowid, tweet_id, tweet FROM tweets "
		"WHERE "
		"(sentiment = '') "
		"ORDER BY tweet_id "
		"LIMIT %d " % (args.num))
	results = sql.execute(query)

	logger.info("Analyzing up to %d tweets." % (args.num))

	batch_size = 25

	batch = []
	num_analyzed = 0

	for row in results:
	
		#
        # Hit our batch size?  Analyze it.
        #
		if len(batch) >= batch_size:
			batch = analyze(comprehend, batch, args.fake, args.skip)
			writeResults(sql, batch)
			num_analyzed += len(batch)
			batch = []

		batch.append({
			"rowid": row["rowid"],
			"tweet": row["tweet"]
			})
	
	#
	# Analyze whatever might be left.
	#
	if batch:
		batch = analyze(comprehend, batch, args.fake, args.skip)
		writeResults(sql, batch)
		num_analyzed += len(batch)


	cost = 0.0003 * num_analyzed
	logger.info("total_tweets_analyzed=%d" % num_analyzed)
	logger.info("total_aws_cost=%.4f" % cost)
	if args.fake:
		logger.info("BUT--this was run with --fake, so your total cost is really ZERO! :-)")

	logger.info("ok=1")

	#
	# Flush stdout as that doesn't seem to happen regularly in Docker
	# This is mostly of use when debugging.
	#
	sys.stdout.flush()

if not args.loop:
	main(args)

else:
	while True:
		main(args)
		logger.info("Sleeping for %d seconds..." % args.loop)
		time.sleep(args.loop)
		logger.info("Waking up!")




